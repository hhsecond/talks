{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from datautils import FizBuzDataSet, print_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Utils\n",
    "All those data-shuffling, indexing-through-data and meddling-with-batch-size had gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FizBuzDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.decoder(dataset[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = 64\n",
    "loader = data.DataLoader(dataset, batch_size=bsize, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in loader:\n",
    "    print(data[0].shape, data[1].shape, len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FizBuzNet, JITFizBuzNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.nn.Module\n",
    "- torch.nn\n",
    "- forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FizBuzNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([param.numel() * param.element_size() for param in net.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch core has a convenient package written for training, validation and testing called [ignite](https://github.com/pytorch/ignite/blob/master/examples/mnist.py), But we'll be using normal python flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outli = ['fizbuz', 'buz', 'fiz', 'number']\n",
    "epochs = 500\n",
    "batches = 64\n",
    "lr = 0.01\n",
    "net = FizBuzNet()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        hyp = net(x)\n",
    "        loss = loss_fn(hyp, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if not epoch % 50:\n",
    "        i = 0\n",
    "        x = dataset.decoder(x[i])\n",
    "        y = hyp[i].max(0)[1].item()\n",
    "        pred = outli[y]\n",
    "        print_out(epoch, x, pred, loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "- Try with PDB to see the effect of zero_grad()\n",
    "- Check the value change after `optimizer.step()`\n",
    "- Try with PDB to see how dynamic graph easify the debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in loader:\n",
    "        pdb.set_trace()\n",
    "        optimizer.zero_grad()\n",
    "        hyp = net(x)\n",
    "        loss = loss_fn(hyp, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if not epoch % 50:\n",
    "        i = 0\n",
    "        x = dataset.decoder(x[i])\n",
    "        y = hyp[i].max(0)[1].item()\n",
    "        pred = outli[y]\n",
    "        print_out(epoch, x, pred, loss.item())\n",
    "\"\"\"\n",
    "check for\n",
    "net.hidden.weight[0, 0]\n",
    "net.hidden.weight.grad[0, 0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace, out = torch.jit.get_trace_graph(net, x)\n",
    "print(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling & JIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you can add any profiler to find out the bottle necks, torch profiler gives you more clear stats about the neural network level profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FizBuzNet()\n",
    "x, y = next(loader.__iter__())\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.profiler.profile() as prof:\n",
    "    net(x)\n",
    "print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = JITFizBuzNet()\n",
    "\n",
    "x, y = next(loader.__iter__())\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    net(x)\n",
    "print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(loader.__iter__())\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    net(x)\n",
    "print(prof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorboardX or FlashLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SummaryWriter(comment='FizBuzNet') as w:\n",
    "    w.add_graph(net, (x, ))\n",
    "# tensorboard --logdir runs\n",
    "# https://github.com/lanpa/tensorboard-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FlashLight is still under development it hasn't reached this stage but soon will be\n",
    "from flashlight import FlashLight\n",
    "flashlight = FlashLight(net)\n",
    "flashlight.show_dynamic(x)\n",
    "flashlight.show_static(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'fizbuznet.pth')\n",
    "# net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = FizBuzNet()\n",
    "new_net.load_state_dict(torch.load('fizbuznet.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX - The interop builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch onnx uses jit trace module to trace through the graph. The traced output is used to convert the model to onnx format and hence non-deterministic conditionals or loops in the model file might cause wrong result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(64, 10)\n",
      "      %1 : Float(100, 10)\n",
      "      %2 : Float(100)\n",
      "      %3 : Float(4, 100)\n",
      "      %4 : Float(4)) {\n",
      "  %5 : Float(64, 100) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%0, %1, %2), scope: FizBuzNet/Linear[hidden]\n",
      "  %6 : Float(64, 100) = onnx::Sigmoid(%5), scope: FizBuzNet\n",
      "  %7 : Float(64, 4) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%6, %3, %4), scope: FizBuzNet/Linear[out]\n",
      "  %8 : Float(64, 4) = onnx::Sigmoid(%7), scope: FizBuzNet\n",
      "  return (%8);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onnx.export(net, x, \"fizbuz.proto\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the populare frameworks have support for ONNX models and all of them are actievely developed.\n",
    "- [ONNX Examples](https://github.com/onnx/tutorials/tree/master/tutorials)\n",
    "- [TensorFlow Importer](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxTensorflowImport.ipynb)\n",
    "- [CNTK Importer](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxCntkImport.ipynb)\n",
    "- [MxNet Importer](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxMxnetImport.ipynb)\n",
    "- [CoreML Importer](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxCoremlImport.ipynb)\n",
    "- [Caffe2 Importer](https://github.com/onnx/tutorials/blob/master/tutorials/OnnxCaffe2Import.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
